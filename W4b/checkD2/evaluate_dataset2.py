# import pickle
# import numpy as np
# import pandas as pd
# from sklearn.metrics import classification_report

# # ğŸ“‚ **Äá»‹nh nghÄ©a Ä‘Æ°á»ng dáº«n file**
# PREPROCESSED_DATASET_PATH = "W4b/checkD2/preprocessed_dataset2.pkl"  # Dataset2 Ä‘Ã£ tiá»n xá»­ lÃ½
# LABEL_ENCODER_PATH = "W4b/checkD2/label_encoder.pkl"  # LabelEncoder Ä‘Ã£ train trÆ°á»›c Ä‘Ã³
# TRAIN_COLUMNS_PATH = "W4b/train_columns.pkl"  # Danh sÃ¡ch Ä‘áº·c trÆ°ng Ä‘Ã£ train
# MODEL_PATHS = {
#     "Logistic Regression": "W4b/models/model_logistic_regression.pkl",
#     "Random Forest": "W4b/models/model_random_forest.pkl",
#     "XGBoost": "W4b/models/model_xgboost.pkl"
# }

# # ğŸ“Œ **1. Load dataset Ä‘Ã£ tiá»n xá»­ lÃ½**
# print("ğŸ“‚ Äang táº£i dataset má»›i...")
# with open(PREPROCESSED_DATASET_PATH, "rb") as f:
#     data = pickle.load(f)

# # **TÃ¡ch táº­p test:**
# X_test = data.drop(columns=["cvss_encoded"])  # Loáº¡i bá» nhÃ£n
# y_test = data["cvss_encoded"].values  # NhÃ£n Ä‘Ã£ mÃ£ hÃ³a

# print(f"ğŸ“Š Dá»¯ liá»‡u test cÃ³ {X_test.shape[0]} máº«u, {X_test.shape[1]} Ä‘áº·c trÆ°ng.")

# # ğŸ“Œ **2. Load danh sÃ¡ch Ä‘áº·c trÆ°ng TF-IDF Ä‘Ã£ train**
# print("ğŸ“‚ Äang táº£i danh sÃ¡ch Ä‘áº·c trÆ°ng Ä‘Ã£ train...")
# with open(TRAIN_COLUMNS_PATH, "rb") as f:
#     train_columns = pickle.load(f)

# # ğŸ“Œ **Äá»“ng bá»™ táº­p test vá»›i danh sÃ¡ch cá»™t Ä‘Ã£ train**
# missing_cols = set(train_columns) - set(X_test.columns)
# extra_cols = set(X_test.columns) - set(train_columns)

# print(f"ğŸ“Š Äang kiá»ƒm tra tÃ­nh nháº¥t quÃ¡n cá»§a táº­p test...")
# print(f"ğŸ› ï¸  Sá»‘ cá»™t thiáº¿u trong táº­p test: {len(missing_cols)}")
# print(f"ğŸ› ï¸  Sá»‘ cá»™t dÆ° trong táº­p test: {len(extra_cols)}")

# # **ThÃªm cá»™t thiáº¿u vá»›i giÃ¡ trá»‹ 0 vÃ  loáº¡i bá» cá»™t dÆ°**
# X_test = X_test.reindex(columns=train_columns, fill_value=0)

# print(f"ğŸ“Š Sá»‘ Ä‘áº·c trÆ°ng sau khi Ä‘á»“ng bá»™: {X_test.shape[1]} (Train: {len(train_columns)})")

# # ğŸ“Œ **3. Load LabelEncoder Ä‘á»ƒ chuyá»ƒn Ä‘á»•i nhÃ£n**
# print("ğŸ“‚ Äang táº£i LabelEncoder...")
# with open(LABEL_ENCODER_PATH, "rb") as f:
#     label_encoder = pickle.load(f)

# # ğŸ“Œ **4. ÄÃ¡nh giÃ¡ tá»«ng mÃ´ hÃ¬nh**
# for model_name, model_path in MODEL_PATHS.items():
#     print(f"\nğŸš€ Äang Ä‘Ã¡nh giÃ¡: {model_name}...")

#     # **Load mÃ´ hÃ¬nh**
#     with open(model_path, "rb") as f:
#         model = pickle.load(f)

#     # **Dá»± Ä‘oÃ¡n**
#     y_pred = model.predict(X_test)

#     # **Chuyá»ƒn Ä‘á»•i y_pred tá»« sá»‘ sang nhÃ£n**
#     y_pred_labels = label_encoder.inverse_transform(y_pred)
#     y_test_labels = label_encoder.inverse_transform(y_test)

#     # **In káº¿t quáº£ Ä‘Ã¡nh giÃ¡**
#     print(f"\nğŸ“Š Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ {model_name}:")
#     print(classification_report(y_test_labels, y_pred_labels))

# print("\nâœ… ÄÃ¡nh giÃ¡ hoÃ n thÃ nh!")


import pickle
import numpy as np
import pandas as pd
import os
from sklearn.metrics import classification_report

# Get the directory containing this script
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
# Get the project root (two directories up from the script)
PROJECT_ROOT = os.path.abspath(os.path.join(SCRIPT_DIR, "..", ".."))

# ğŸ“‚ **Äá»‹nh nghÄ©a Ä‘Æ°á»ng dáº«n file vá»›i Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i**
PREPROCESSED_DATASET_PATH = os.path.join(PROJECT_ROOT, "W4b", "checkD2", "preprocessed_dataset2.pkl")
LABEL_ENCODER_PATH = os.path.join(PROJECT_ROOT, "W4b", "checkD2", "label_encoder.pkl")
TRAIN_COLUMNS_PATH = os.path.join(PROJECT_ROOT, "W4b", "train_columns.pkl")
MODEL_PATHS = {
    "Logistic Regression": os.path.join(PROJECT_ROOT, "W4b", "models", "model_logistic_regression.pkl"),
    "Random Forest": os.path.join(PROJECT_ROOT, "W4b", "models", "model_random_forest.pkl"),
    "XGBoost": os.path.join(PROJECT_ROOT, "W4b", "models", "model_xgboost.pkl")
}

# Äáº£m báº£o Ä‘Æ°á»ng dáº«n Ä‘Ãºng
print(f"ğŸ“‚ ÄÆ°á»ng dáº«n dá»¯ liá»‡u: {PREPROCESSED_DATASET_PATH}")
print(f"ğŸ“‚ ÄÆ°á»ng dáº«n label encoder: {LABEL_ENCODER_PATH}")
print(f"ğŸ“‚ ÄÆ°á»ng dáº«n danh sÃ¡ch cá»™t: {TRAIN_COLUMNS_PATH}")

with open(TRAIN_COLUMNS_PATH, "rb") as f:
    train_columns = pickle.load(f)

print(f"Sá»‘ Ä‘áº·c trÆ°ng khi huáº¥n luyá»‡n: {len(train_columns)}")

# ğŸ“Œ **1. Load dataset Ä‘Ã£ tiá»n xá»­ lÃ½**
print("ğŸ“‚ Äang táº£i dataset má»›i...")
try:
    with open(PREPROCESSED_DATASET_PATH, "rb") as f:
        data = pickle.load(f)
except FileNotFoundError:
    print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file {PREPROCESSED_DATASET_PATH}")
    exit(1)

# **TÃ¡ch táº­p test:**
X_test = data.drop(columns=["cvss_encoded"])  # Loáº¡i bá» nhÃ£n
y_test = data["cvss_encoded"].values  # NhÃ£n Ä‘Ã£ mÃ£ hÃ³a

print(f"ğŸ“Š Dá»¯ liá»‡u test cÃ³ {X_test.shape[0]} máº«u, {X_test.shape[1]} Ä‘áº·c trÆ°ng.")

# ğŸ“Œ **2. Load danh sÃ¡ch Ä‘áº·c trÆ°ng TF-IDF Ä‘Ã£ train**
print("ğŸ“‚ Äang táº£i danh sÃ¡ch Ä‘áº·c trÆ°ng Ä‘Ã£ train...")
try:
    with open(TRAIN_COLUMNS_PATH, "rb") as f:
        train_columns = pickle.load(f)
except FileNotFoundError:
    print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file {TRAIN_COLUMNS_PATH}")
    exit(1)

# ğŸ“Œ **Äá»“ng bá»™ táº­p test vá»›i danh sÃ¡ch cá»™t Ä‘Ã£ train**
print(f"ğŸ“Š Sá»‘ cá»™t trong dá»¯ liá»‡u test: {len(X_test.columns)}")
print(f"ğŸ“Š Sá»‘ cá»™t trong dá»¯ liá»‡u train: {len(train_columns)}")

missing_cols = set(train_columns) - set(X_test.columns)
extra_cols = set(X_test.columns) - set(train_columns)

print(f"ğŸ“Š Äang kiá»ƒm tra tÃ­nh nháº¥t quÃ¡n cá»§a táº­p test...")
print(f"ğŸ› ï¸  Sá»‘ cá»™t thiáº¿u trong táº­p test: {len(missing_cols)}")
if len(missing_cols) > 0:
    print(f"ğŸ› ï¸  VÃ­ dá»¥ vá» má»™t sá»‘ cá»™t thiáº¿u: {list(missing_cols)[:5]}")
print(f"ğŸ› ï¸  Sá»‘ cá»™t dÆ° trong táº­p test: {len(extra_cols)}")
if len(extra_cols) > 0:
    print(f"ğŸ› ï¸  VÃ­ dá»¥ vá» má»™t sá»‘ cá»™t dÆ°: {list(extra_cols)[:5]}")

# **Táº¡o DataFrame má»›i vá»›i cÃ¡c cá»™t giá»‘ng táº­p train**
X_test_aligned = pd.DataFrame(0, index=X_test.index, columns=train_columns)

# **Sao chÃ©p dá»¯ liá»‡u tá»« X_test sang X_test_aligned cho cÃ¡c cá»™t tá»“n táº¡i trong cáº£ hai**
common_cols = set(X_test.columns).intersection(set(train_columns))
for col in common_cols:
    X_test_aligned[col] = X_test[col]

print(f"ğŸ“Š Sá»‘ Ä‘áº·c trÆ°ng sau khi Ä‘á»“ng bá»™: {X_test_aligned.shape[1]} (Train: {len(train_columns)})")

# ğŸ“Œ **3. Load LabelEncoder Ä‘á»ƒ chuyá»ƒn Ä‘á»•i nhÃ£n**
print("ğŸ“‚ Äang táº£i LabelEncoder...")
try:
    with open(LABEL_ENCODER_PATH, "rb") as f:
        label_encoder = pickle.load(f)
except FileNotFoundError:
    print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file {LABEL_ENCODER_PATH}")
    exit(1)

# ğŸ“Œ **4. ÄÃ¡nh giÃ¡ tá»«ng mÃ´ hÃ¬nh**
for model_name, model_path in MODEL_PATHS.items():
    print(f"\nğŸš€ Äang Ä‘Ã¡nh giÃ¡: {model_name}...")

    # **Load mÃ´ hÃ¬nh**
    try:
        with open(model_path, "rb") as f:
            model = pickle.load(f)
    except FileNotFoundError:
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y mÃ´ hÃ¬nh {model_path}")
        continue

    # **Dá»± Ä‘oÃ¡n**
    try:
        y_pred = model.predict(X_test_aligned)
        
        # **Chuyá»ƒn Ä‘á»•i y_pred tá»« sá»‘ sang nhÃ£n**
        y_pred_labels = label_encoder.inverse_transform(y_pred)
        y_test_labels = label_encoder.inverse_transform(y_test)

        # **In káº¿t quáº£ Ä‘Ã¡nh giÃ¡**
        print(f"\nğŸ“Š Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ {model_name}:")
        print(classification_report(y_test_labels, y_pred_labels))
    except Exception as e:
        print(f"âŒ Lá»—i khi dá»± Ä‘oÃ¡n vá»›i mÃ´ hÃ¬nh {model_name}: {str(e)}")

print("\nâœ… ÄÃ¡nh giÃ¡ hoÃ n thÃ nh!")